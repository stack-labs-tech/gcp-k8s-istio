= Resiliency

The goal of this step is to use the service mesh to improve the resiliency of our system.

[#prevent-fault]
== Prevent fault

The *Search* application has a parameter which allow to define the error rate of its main endpoint. You can activate it by setting an environment variable name `SEARCH_ERROR_RATE` to a value between 0 and 100.

In this step, we will deploy *UI* and *Search* configured with an error rate of 50%

[source,yaml]
----
apiVersion: v1
kind: Namespace
metadata:
  labels:
    istio-injection: enabled
  name: workshop
---
apiVersion: v1
kind: Service
metadata:
  namespace: workshop
  name: search
  labels:
    app: search
spec:
  ports:
    - name: http
      port: 8080
  selector:
    app: search
---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: workshop
  labels:
    app: search
    version: v1
  name: search-v1
spec:
  selector:
    matchLabels:
      app: search
      version: v1
  template:
    metadata:
      labels:
        app: search
        version: v1
    spec:
      containers:
        - image: stacklabs/gke-and-istio-search:latest
          imagePullPolicy: Always
          env:
            - name: SPRING_CLOUD_GCP_LOGGING_PROJECT_ID
              value: istio-csm
            - name: SEARCH_VERSION
              value: v1
            - name: SEARCH_EVENT
              value: "GKE + Istio Formation"
            - name: SEARCH_ERROR_RATE
              value: "50" # <1>
          livenessProbe:
            httpGet:
              path: /actuator/health
              port: 8181
            initialDelaySeconds: 20
          name: search
          resources:
            requests:
              memory: "512Mi"
              cpu: 1
            limits:
              memory: "512Mi"
              cpu: 1
          ports:
            - containerPort: 8080
              name: http
              protocol: TCP
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  namespace: workshop
  name: search
spec:
  hosts:
    - search
  http:
    - route:
        - destination:
            host: search
            subset: version-1
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  namespace: workshop
  name: search
spec:
  host: search
  subsets:
    - name: version-1
      labels:
        version: v1
---
apiVersion: v1
kind: Service
metadata:
  namespace: workshop
  name: ui
  labels:
    app: ui
spec:
  ports:
    - name: http
      port: 8080
  selector:
    app: ui
---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: workshop
  labels:
    app: ui
    version: v1
  name: ui-v1
spec:
  selector:
    matchLabels:
      app: ui
      version: v1
  template:
    metadata:
      labels:
        app: ui
        version: v1
    spec:
      containers:
        - image: stacklabs/gke-and-istio-ui:latest
          imagePullPolicy: Always
          env:
            - name: SPRING_CLOUD_GCP_LOGGING_PROJECT_ID
              value: istio-csm
            - name: UI_VERSION
              value: v1
            - name: UI_SEARCHURL
              value: http://search:8080/
          livenessProbe:
            httpGet:
              path: /actuator/health
              port: 8181
            initialDelaySeconds: 20
          name: ui
          resources:
            requests:
              memory: "512Mi"
              cpu: 1
            limits:
              memory: "512Mi"
              cpu: 1
          ports:
            - containerPort: 8080
              name: http
              protocol: TCP
---
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  namespace: workshop
  name: ui
spec:
  selector:
    istio: ingressgateway
  servers:
    - port:
        number: 80
        name: http
        protocol: HTTP
      hosts:
        - "*"
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  namespace: workshop
  name: ui
spec:
  hosts:
    - "*"
  gateways:
    - ui
  http:
    - route:
        - destination:
            host: ui
            subset: version-1
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  namespace: workshop
  name: ui
spec:
  host: ui
  subsets:
    - name: version-1
      labels:
        version: v1
----
1. The error rate of the endpoint of *Search* application in this case.


If we execute a multiple sequential calls, we will have the following results:

[source,bash]
----
Λ\:$ while true; curl -qs 35.228.32.51; echo; end
{"timestamp":"2019-05-20T18:45:55.193+0000","path":"/","status":500,"error":"Internal Server Error","message":"500 Internal Server Error"}
{"timestamp":"2019-05-20T18:45:55.836+0000","path":"/","status":500,"error":"Internal Server Error","message":"500 Internal Server Error"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:45:57.511Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:45:59.037Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:45:59.735Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:46:01.344Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:46:02.402Z"}
{"timestamp":"2019-05-20T18:46:02.787+0000","path":"/","status":500,"error":"Internal Server Error","message":"500 Internal Server Error"}
{"timestamp":"2019-05-20T18:46:03.409+0000","path":"/","status":500,"error":"Internal Server Error","message":"500 Internal Server Error"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:46:04.916Z"}
{"timestamp":"2019-05-20T18:46:05.105+0000","path":"/","status":500,"error":"Internal Server Error","message":"500 Internal Server Error"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:46:06.251Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:46:07.766Z"}
----

We are seeing a typical case where our first application should prevent error(s) from an underlying service. To do so with Istio, we can use a built in functionality to *Retry* (https://istio.io/docs/reference/config/networking/v1alpha3/virtual-service/#HTTPRetry[documentation]) calls on error

If you apply the following YAML to override the *VirtualService* of the *Search* service, you will activate an automatic retry on every errors:

[source, bash]
----
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  namespace: workshop
  name: search
spec:
  hosts:
    - search
  http:
    - route:
        - destination:
            host: search
            subset: version-1
      retries:
        attempts: 5
        perTryTimeout: 1s
----

We can follow our long running curl process and see the number of error reduce a lot:

[source, bash]
----
Λ\:$ while true; curl -qs 35.228.32.51; echo; end
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:37.61Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:38.495Z"}
{"timestamp":"2019-05-20T18:51:38.795+0000","path":"/","status":500,"error":"Internal Server Error","message":"500 Internal Server Error"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:39.886Z"} <1>
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:40.451Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:41.883Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:42.914Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:43.428Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:44.234Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:45.271Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:45.884Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:46.469Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:47.607Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:48.533Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:49.437Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:51.049Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:51.815Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:53.267Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:54.36Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:54.873Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T18:51:56.75Z"}
----
1. The *YAML* has been applied at this time.

Due to probability, this will not reduce all errors in our case, because with a *ERROR_RATE* of 50% and 5 retry, some error can still happen.

[#traffic-limiting]
== Traffic Limiting

We can restrict traffic between to service, especially when we know too many request from one to another can trigger so problem on both micro-services.
To do so, we can use the *TrafficPolicy* element define in the *DestinationRule* to prevent too many request at the same time.

[source,yaml]
----
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  namespace: workshop
  name: search
spec:
  host: search
  trafficPolicy:
    connectionPool:
      http:
        http1MaxPendingRequests: 1
        maxRequestsPerConnection: 1
  subsets:
    - name: version-1
      labels:
        version: v1
----

To see it in action, you'll have to do a lots of request because Envoy keep track of each and try to orchestrate them well to reduce the number of errors.

So, with the *Docker* *Siege* command, we can see some errors occurs when a lots of request are made in parallels.

[source, bash]
----
Λ\:~ kevin $ docker run --rm -it yokogawa/siege 35.228.32.51 -c 100 -v
** SIEGE 3.0.5
** Preparing 100 concurrent users for battle.
The server is now under siege...
HTTP/1.1 500   0.17 secs:     136 bytes ==> GET  /
HTTP/1.1 500   0.18 secs:     136 bytes ==> GET  /
HTTP/1.1 500   0.24 secs:     136 bytes ==> GET  /
HTTP/1.1 200   0.25 secs:      99 bytes ==> GET  /
HTTP/1.1 500   0.29 secs:     136 bytes ==> GET  /
HTTP/1.1 500   0.29 secs:     136 bytes ==> GET  /
HTTP/1.1 500   0.35 secs:     136 bytes ==> GET  /
HTTP/1.1 200   0.50 secs:      99 bytes ==> GET  /
HTTP/1.1 200   0.50 secs:      99 bytes ==> GET  /
HTTP/1.1 200   1.51 secs:      99 bytes ==> GET  /
HTTP/1.1 500   0.53 secs:     136 bytes ==> GET  /
HTTP/1.1 200   1.56 secs:      99 bytes ==> GET  /
HTTP/1.1 200   0.57 secs:      98 bytes ==> GET  /
HTTP/1.1 200   0.57 secs:      99 bytes ==> GET  /
HTTP/1.1 200   0.57 secs:      99 bytes ==> GET  /
HTTP/1.1 500   0.62 secs:     136 bytes ==> GET  /
HTTP/1.1 500   0.61 secs:     136 bytes ==> GET  /
HTTP/1.1 500   0.46 secs:     136 bytes ==> GET  /
HTTP/1.1 200   1.64 secs:      98 bytes ==> GET  /
HTTP/1.1 200   1.65 secs:      99 bytes ==> GET  /
HTTP/1.1 200   1.01 secs:      98 bytes ==> GET  /
HTTP/1.1 200   1.02 secs:      99 bytes ==> GET  /
HTTP/1.1 500   0.18 secs:     136 bytes ==> GET  /
HTTP/1.1 200   1.04 secs:      99 bytes ==> GET  /
HTTP/1.1 200   1.10 secs:      99 bytes ==> GET  /
HTTP/1.1 500   0.42 secs:     136 bytes ==> GET  /
HTTP/1.1 200   1.41 secs:      99 bytes ==> GET  /
HTTP/1.1 200   1.43 secs:      99 bytes ==> GET  /
HTTP/1.1 200   0.74 secs:      99 bytes ==> GET  /
HTTP/1.1 200   1.30 secs:      99 bytes ==> GET  /
HTTP/1.1 500   0.18 secs:     136 bytes ==> GET  /
HTTP/1.1 500   0.46 secs:     136 bytes ==> GET  /
HTTP/1.1 200   1.50 secs:      99 bytes ==> GET  /
HTTP/1.1 200   1.04 secs:      99 bytes ==> GET  /
HTTP/1.1 500   0.13 secs:     136 bytes ==> GET  /
HTTP/1.1 200   1.57 secs:      99 bytes ==> GET  /
HTTP/1.1 200   1.64 secs:      99 bytes ==> GET  /
HTTP/1.1 200   1.65 secs:      99 bytes ==> GET  /
^C
Lifting the server siege...      done.

Transactions:		         146 hits
Availability:		       86.90 %
Elapsed time:		        3.22 secs
Data transferred:	        0.02 MB
Response time:		        1.16 secs
Transaction rate:	       45.34 trans/sec
Throughput:		        0.01 MB/sec
Concurrency:		       52.72
Successful transactions:         146
Failed transactions:	          22
Longest transaction:	        2.03
Shortest transaction:	        0.13
----

During this operation, you also can launch a curl inside a `while` to see the actual response:

[source,bash]
----
Λ\:$ while true;  curl -qs 35.228.32.51; echo; end
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:05:20.255Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:05:21.666Z"}
{"timestamp":"2019-05-20T20:05:21.844+0000","path":"/","status":500,"error":"Internal Server Error","message":"503 Service Unavailable"}
{"timestamp":"2019-05-20T20:05:22.005+0000","path":"/","status":500,"error":"Internal Server Error","message":"503 Service Unavailable"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:05:22.732Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:05:23.393Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:05:24.464Z"}
----

More:

* You can follow execution logs of the envoy proxy to see what's happening during traffic exclusion
* You can follow errors rate inside the stackdriver console to see the number of request handled by each pods

[#pool-ejection]
== Pool Ejection

This principe allows Istio to cancel all traffic to a pod when this one returns too many errors ( >= 502 http error code).
That will reduce the incoming traffic, letting the pod cool down for few minutes before coming back to the pool.

NOTE: To see this in action, you should install *stern* which let us follow logs of multiple pods at once and adding prefix / coloration to each logs

In this step, we will publish another version of the *Search* v1 but with a high error rate. To do so, you should apply the following *YAML*

[source,yaml]
----
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: workshop
  labels:
    app: search
    version: v1
  name: search-v1-with-too-many-errors
spec:
  selector:
    matchLabels:
      app: search
      version: v1
  template:
    metadata:
      labels:
        app: search
        version: v1
    spec:
      containers:
        - image: stacklabs/gke-and-istio-search:latest
          imagePullPolicy: Always
          env:
            - name: SPRING_CLOUD_GCP_LOGGING_PROJECT_ID
              value: istio-csm
            - name: SEARCH_VERSION
              value: v1
            - name: SEARCH_EVENT
              value: "GKE + Istio Formation"
            - name: SEARCH_ERROR_RATE
              value: "75"
          livenessProbe:
            httpGet:
              path: /actuator/health
              port: 8181
            initialDelaySeconds: 20
          name: search
          resources:
            requests:
              memory: "512Mi"
              cpu: 1
            limits:
              memory: "512Mi"
              cpu: 1
          ports:
            - containerPort: 8080
              name: http
              protocol: TCP
----

Use stern to follow logs of both pods at same time:

[source,bash]
----
Λ\:~ kevin $ kt search -t -c search
search-v1-65b684bd54-bbt4d search 2019-05-20T20:20:48.025575791Z {"traceId":"b32b5b724cf05561","spanId":"4b49b5f6ab7cd9c4","spanExportable":"false","X-B3-ParentSpanId":"e682d580f4bebe9f","parentId":"e682d580f4bebe9f","timestampSeconds":1558383648,"timestampNan
os":25000000,"severity":"INFO","thread":"parallel-1","logger":"com.stack_labs.workshop.gkeandistio.search.SearchHandler","message":"Search service called and respond with event \"GKE + Istio Formation:v1\" ","context":"default","logging.googleapis.com/trace":"
projects/istio-csm/traces/0000000000000000b32b5b724cf05561","logging.googleapis.com/spanId":"4b49b5f6ab7cd9c4"}
search-v1-with-too-many-errors-5cc9fd5dcf-9ff2k search 2019-05-20T20:20:52.134866938Z {"traceId":"4a373ff833ff37a8","spanId":"a5aa55c7e3820b25","spanExportable":"false","X-B3-ParentSpanId":"ee835d8558d426c7","parentId":"ee835d8558d426c7","timestampSeconds":155
8383652,"timestampNanos":132000000,"severity":"ERROR","thread":"reactor-http-epoll-3","logger":"org.springframework.boot.autoconfigure.web.reactive.error.AbstractErrorWebExceptionHandler... }
search-v1-65b684bd54-bbt4d search 2019-05-20T20:20:49.493012601Z {"traceId":"7850535d1067be34","spanId":"7c0995afdd1986eb","spanExportable":"false","X-B3-ParentSpanId":"cdc10b5705e0461c","parentId":"cdc10b5705e0461c","timestampSeconds":1558383649,"timestampNan
os":491000000,"severity":"INFO","thread":"parallel-1","logger":"com.stack_labs.workshop.gkeandistio.search.SearchHandler","message":"Search service called and respond with event \"GKE + Istio Formation:v1\" ","context":"default","logging.googleapis.com/trace":
"projects/istio-csm/traces/00000000000000007850535d1067be34","logging.googleapis.com/spanId":"7c0995afdd1986eb"}
search-v1-with-too-many-errors-5cc9fd5dcf-9ff2k search 2019-05-20T20:20:52.134866938Z {"traceId":"4a373ff833ff37a8","spanId":"a5aa55c7e3820b25","spanExportable":"false","X-B3-ParentSpanId":"ee835d8558d426c7","parentId":"ee835d8558d426c7","timestampSeconds":155
8383652,"timestampNanos":132000000,"severity":"ERROR","thread":"reactor-http-epoll-3","logger":"org.springframework.boot.autoconfigure.web.reactive.error.AbstractErrorWebExceptionHandler... }
----

And you will use the `curl` command to execute multiple call sequentially:

[source,bash]
----
Λ\:$ while true;  curl -qs 35.228.32.51; echo; end
{"timestamp":"2019-05-20T20:18:35.311+0000","path":"/","status":500,"error":"Internal Server Error","message":"500 Internal Server Error"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:18:36.639Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:18:38.312Z"}
{"timestamp":"2019-05-20T20:18:38.901+0000","path":"/","status":500,"error":"Internal Server Error","message":"500 Internal Server Error"}
{"timestamp":"2019-05-20T20:18:39.265+0000","path":"/","status":500,"error":"Internal Server Error","message":"500 Internal Server Error"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:18:40.781Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:18:41.811Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:18:43.13Z"}
{"timestamp":"2019-05-20T20:18:43.737+0000","path":"/","status":500,"error":"Internal Server Error","message":"500 Internal Server Error"}
----

You can see a lots of errors comming from the same pod. To use the *Pool Ejection* (https://istio.io/docs/reference/config/networking/v1alpha3/destination-rule/#OutlierDetection), you have to apply this *YAML*:

[source,YAML]
----
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  namespace: workshop
  name: search
spec:
  host: search
  subsets:
    - name: version-1
      labels:
        version: v1
      trafficPolicy:
        connectionPool:
          http: {}
          tcp: {}
        outlierDetection:
          baseEjectionTime: 10.000s
          consecutiveErrors: 1
          interval: 1.000s
          maxEjectionPercent: 100
----

By following the logs in the *stern* view (you can only follow pods *search-v1-with* pattern), you will find a some moment where the pod didn't receive any request... almost every 10 seconds.

The execution command should look like this:

[source, bash]
---
Λ\:$ while true;  curl -qs 35.228.32.51; echo; end
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:43:36.912Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:43:38.799Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:43:40.678Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:43:41.488Z"}
{"timestamp":"2019-05-20T20:43:42.134+0000","path":"/","status":500,"error":"Internal Server Error","message":"503 Service Unavailable"} <1>
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:43:43.523Z"} <2>
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:43:44.678Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:43:45.872Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:43:46.984Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:43:48.486Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:43:49.791Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:43:50.244Z"}
{"hello":"GKE + Istio Formation","from":"ui (v1) => search (v1)","date":"2019-05-20T20:43:52.101Z"}
---
<1> The pods answer with a invalid response, it will be evicted during 10s
<2> Next requests are only handle by other pods

More:

* You can use the previously created dashboard to see the request count of each pods inside the cluster

NOTE: The ejection-time is *equal to the product of minimum ejection duration and the number of times the host has been ejected*


