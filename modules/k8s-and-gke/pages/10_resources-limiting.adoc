[#resources-limiting]
= Resource Limiting

So far we have been deploying _Pods_ without really taking care of how much resources were allocated for us by Kubernetes. However specifying resources can help Kubernetes scheduler, as mentioned in the https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/[documentation]:

> When Containers have resource requests specified, the scheduler can make better decisions about which nodes to place Pods on. And when Containers have their limits specified, contention for resources on a node can be handled in a specified manner

== Tutorial: Specifying resources request and limit

First, let's check the current resources usage using `kubectl top`:

```shell
kubectl top pods
```

You should see something similar to this:

image::kubectl-top-pods.png[]

We can also check the cluster overall memory and CPU usage (node per node) using:

```shell
kubectl top nodes
```

image::kubectl-top-nodes.png[]

We will now add resources request and limit for memory and CPU to our `travel-manager` application:

```yaml
requests:
  cpu: 0.2
  memory: "200Mi"
limits:
  cpu: 0.2
  memory: "300Mi"
```

What we are saying here is:

* Each `travel-manager` container should have exactly 0.2 CPU (== 20% of a GCP Core)
* Each `travel-manager` container should have at least 200MiB memory allocated, and at most 300MiB.

TIP: Instead of writing `0.2` CPU we could have expressed this in "millicores" by requesting `200m`.

Replace our old deployment by the same deployment with resources requests/limits:

```shell
kubectl apply -f manifests/app/deployments/travel-manager-with-limits.yaml
```

Let's also update our Redis instance with some memory resources request/limit:

```shell
kubectl apply -f manifests/app/deployments/redis-with-memory.yaml
```

After a few seconds you should see the updated resources:

```shell
kubectl top pods
```

What happens if the sum of all requested resources are over the total available resources on nodes ? Well... let's try !

We have a cluster of 3 nodes of 2 GCP Core each, which mean we should be able to assign around 30 Pods of 200m CPU each. Let's scale do to exactly that:

```shell
kubectl scale deployments travel-manager --replicas=30
```

=== Quizz

* How many _Pods_ of `travel-manager` were actually deployed ?
* How many _Pods_ of `travel-manager` are staying in `Pending` status ?
* What is the error message on `Pending` _Pods_ ?

==== Hints

```shell
kubectl get pods --field-selector=status.phase='Running'
```

```shell
kubectl get pods --field-selector=status.phase='Pending'
```

```shell
kubectl describe pod <A_PENDING_POD_ID>
```

[#qos]
== Tutorial: Handling QoS classes

Did you notice the different type of quality classes our services had so far ? No ? Now is the time ! As always, describe is your best friend...

```shell
kubectl get po redis --output yaml | grep qos
kubectl get po travel-manager --output yaml | grep qos
kubectl get po distance-calculator --output yaml | grep qos
```

As you can see, there are 3 different types of QoS classes:

|===
|QoS Class |Condition|Description|Eviction on resources claim

|Guaranteed
|Must memory + CPU request & limit set for all containers
|Is guaranteed to run on a node that has available resources
|Pods of this class are the last to be evicted

|Burstable
|At least one container has either CPU or memory request
|Pods are not guaranteed to be on nodes with sufficient resources
|Pods of this class will be evicted after best effort pods but before guaranteed pods

|Best Effort
|No resources limiting is defined
|Pods are not guaranteed to be on nodes with sufficient resources
|Pods of this class will be the first evicted
|===

When possible it is good practice to specify resources requests and limits as it tells Kubernetes scheduler how to scale correctly our _Pods_.

=== Cleanup

Let's scale back to 3 replicas:

```shell
kubectl scale deployments travel-manager --replicas=3
```

== Summary

In this chapter you learned how to add resources requests and limits so that Kubernetes scheduler is able to better manage where it puts our _Pods_. It will also facilitates autoscaling and such.